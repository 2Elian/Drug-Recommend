model_name_or_path: ./model
output_dir: 2048-16-32-epoch-2
train_file: ./data/single_datas.jsonl
task_name: drug-glm4-9b-lora
task_dataset_name: drug-train-80precent
task_des: not des
train_type: A
num_train_epochs: 2
per_device_train_batch_size: 4
gradient_accumulation_steps: 16
learning_rate: 0.0002
max_seq_length: 2048
logging_steps: 1
save_steps: 200
save_total_limit: 1
lr_scheduler_type: constant_with_warmup
warmup_steps: 100
lora_rank: 64
lora_alpha: 16
lora_dropout: 0.05
local_rank: -1
distributed: false
gradient_checkpointing: false
optim: adamw_torch
train_mode: lora
seed: 42
fp16: false
bf16: false
report_to: null
dataloader_num_workers: 8
save_strategy: steps
weight_decay: 0
max_grad_norm: 1
remove_unused_columns: true
drug_file: null
use_focal_loss: false
focal_alpha: 0.75
focal_gamma: 2.0
num_neg_samples: 50
model_type: glm
use_lora: false
eval_file: null
eval_steps: 500
eval_ratio: 0.2
evaluation_strategy: steps
metric_for_best_model: best_score
load_best_model_at_end: false
greater_is_better: true
dataloader_pin_memory: false
dataloader_drop_last: true
use_fsdp: false
fsdp_sharding_strategy: FULL_SHARD
fsdp_offload_params: false
fsdp_min_num_params: 100000000.0
fsdp_backward_prefetch: BACKWARD_PRE
fsdp_forward_prefetch: false
use_deepspeed: false
deepspeed_config: null
use_metrics: false
is_train: false
sp_size: 2
pack_to_max_length: false
use_varlen_attn: false
ignore_index: -100
r1: 0.6
r2: 2.5
lm_loss: false
num_drug: 651

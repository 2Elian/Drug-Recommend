# 实验过程记录

## Q1. Base模型的hidden_state在接入分类器之前 是否需要做一个线性映射?

假设Base Mode的hidden_state是h, 我们进行了如下实验:

1. 测试集(none代表测试集官网看不到非sota的结果, 即代表该方法没有超过之前的方法)

| 实验配置 | F1_score | score |
|------|----------|----------|
| hidden直接接入分类层 | 0.2999 | 0.2515 |
| hidden先接入一个线性映射层至hidden//2,然后接入GELU,再接入分类层 | none | none |

2. 验证集(训练集划分出20%)

| 实验配置 | F1_score | score |
|------|----------|----------|
| hidden直接接入分类层 | 忘记留了，但肯定比下面的高 | 忘记留了，但肯定比下面的高 |
| hidden先接入一个线性映射层至hidden//2,然后接入GELU,再接入分类层 | 0.0197 | 0.0148 |

注意：hidden先接入一个线性映射层至hidden//2,然后接入GELU,再接入分类层的具体分数如下

    "jaccard_th0.5": 0.010018617703807655,
    "precision_avg_th0.5": 0.010115171478057346,
    "recall_avg_th0.5": 0.5527407709864673,
    "f1_avg_th0.5": 0.01975692864183485,
    "score_th0.5": 0.014887773172821252,

    可以看到，具体来说是精确率和Jaccard非常低。

数据集存在极度不平衡的标签（即某些标签的样本数远远大于其他标签，长尾分布问题！），那么模型很容易将大多数预测都归类为 "负类"（没有预测某些标签），从而导致 召回率高（即，能够覆盖到更多真实的标签），但精确度低（即大部分预测可能是错误的标签）。计划在Q2解决！

进一步地，为了验证模型上下文长度对最终分类结果的影响，我们进行了如下实验：
| 上下文长度 | F1_score | score |
|------|----------|----------|
| 2000 | none | none |
| 2500 | 0.0197 | 0.0148 |
| 3000 | 0.0197 | 0.0148 |
| 4000 | 0.0197 | 0.0148 |
| >4000 | oom | oom |


## Q2. 长尾分布问题
![](../images/label_longtail_custom.png)

## Q3. 药品之间的相互排斥性

ing

![](../images/label_cooccurrence_top30.png)

## Q4. 多任务学习
ing

## Q5. 多细粒度特征分类
ing

## Q6. 标签不完备
ing

import json
import asyncio
import re
import os
from tqdm.asyncio import tqdm
from src.utils.templates.llm_prompt_baseline import BASELINE_PROMPT
from src.worker.tool.openai_client import OpenAIClient
from src.worker.tool.tokenizer import Tokenizer

SAVE_INTERVAL = 1  # æ¯å¤„ç†å¤šå°‘ä¸ªæ‚£è€…å°±ç«‹å³ä¿å­˜ä¸€æ¬¡
SAVE_PATH = "/data/lzm/DrugRecommend/resource/output/submit/glm4_submit.json"

async def verify_single_drug(llm_cli, sem, patient, cur_drug, drug_dict):
    async with sem:
        des = drug_dict.get(cur_drug, "[æ— è¯ç‰©æè¿°]")
        hint_prompt = BASELINE_PROMPT["POST_V_PROMPT"].format(
            **BASELINE_PROMPT["FORMAT"],
            init_drug_recommend=cur_drug,
            drug_detail=des,
            sex=patient["æ€§åˆ«"],
            birth_date=patient["å‡ºç”Ÿæ—¥æœŸ"],
            ethnicity=patient["æ°‘æ—"],
            bmi=patient["BMI"],
            visit_date=patient["å°±è¯Šæ—¶é—´"],
            diagnosis_process=patient["è¯Šç–—è¿‡ç¨‹æè¿°"],
            admission_info=patient["å…¥é™¢æƒ…å†µ"],
            current_history=patient["ç°ç—…å²"],
            past_history=patient["æ—¢å¾€å²"],
            chief_complaint=patient["ä¸»è¯‰"],
            discharge_diagnosis=patient["å‡ºé™¢è¯Šæ–­"],
        )

        try:
            result = await llm_cli.generate_answer(hint_prompt)
            result = result.strip().strip('"').strip("'").lower()
        except Exception as e:
            return cur_drug, f"error: {e}"
        return cur_drug, result


async def process_single_patient(llm_cli, sem, patient, pre_drug_set_data, drug_dict):
    patient_id = patient["å°±è¯Šæ ‡è¯†"]
    drug_list = patient["å‡ºé™¢å¸¦è¯åˆ—è¡¨"]

    # step1: è¿‡æ»¤è¯ç‰©
    step1_drug_list = [d for d in drug_list if d in pre_drug_set_data]
    if not step1_drug_list:
        return {"ID": patient_id, "prediction": []}

    filtered = step1_drug_list.copy()
    tasks = [verify_single_drug(llm_cli, sem, patient, d, drug_dict) for d in step1_drug_list]

    for coro in asyncio.as_completed(tasks):
        cur_drug, ans = await coro
        if not ans:
            continue
        match = re.search(r'\b(yes|no)\b', ans)
        if match:
            ans = match.group(1)
        else:
            continue

        if ans == "no" and cur_drug in filtered:
            filtered.remove(cur_drug)

    return {"ID": patient_id, "prediction": filtered}


async def post_process(llm_cli, data_file, pre_drug_set, pre_drug_des, save_json_path, max_concurrent=10):
    sem = asyncio.Semaphore(max_concurrent)

    with open(data_file, "r", encoding="utf-8") as f:
        init_data = json.load(f)
    with open(pre_drug_set, "r", encoding="utf-8") as f:
        pre_drug_set_data = json.load(f)
    with open(pre_drug_des, "r", encoding="utf-8") as f:
        drug_dict = {item["drug"]: item["des"] for item in json.load(f)}

    # -------------------
    # æ”¯æŒæ–­ç‚¹ç»­è·‘
    # -------------------
    completed = {}
    if os.path.exists(save_json_path):
        with open(save_json_path, "r", encoding="utf-8") as f:
            try:
                for record in json.load(f):
                    completed[record["ID"]] = record
            except Exception:
                completed = {}
        print(f"ğŸ” æ£€æµ‹åˆ°å·²å®Œæˆ {len(completed)} æ¡è®°å½•ï¼Œå°†è·³è¿‡é‡å¤æ‚£è€…ã€‚")

    results = list(completed.values())
    pending_patients = [p for p in init_data if p["å°±è¯Šæ ‡è¯†"] not in completed]

    # -------------------
    # ä¸»å¾ªç¯
    # -------------------
    count = 0
    for coro in tqdm(asyncio.as_completed([
        process_single_patient(llm_cli, sem, patient, pre_drug_set_data, drug_dict)
        for patient in pending_patients
    ]), total=len(pending_patients), desc="è¯ç‰©éªŒè¯ä¸­", ncols=100):
        result = await coro
        results.append(result)
        count += 1

        # å®æ—¶ä¿å­˜
        if count % SAVE_INTERVAL == 0:
            with open(save_json_path, "w", encoding="utf-8") as f:
                json.dump(results, f, ensure_ascii=False, indent=2)
            tqdm.write(f"ğŸ’¾ å·²ä¿å­˜ {len(results)} æ¡ç»“æœè‡³ {save_json_path}")

    # æœ€ç»ˆä¿å­˜
    with open(save_json_path, "w", encoding="utf-8") as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
    print(f"âœ… å®Œæˆï¼Œæ€»è®¡ {len(results)} ä½æ‚£è€…ã€‚ç»“æœå·²ä¿å­˜è‡³ï¼š{save_json_path}")


if __name__ == "__main__":
    tokenizer_instance = Tokenizer(
        model_name="/data1/nuist_llm/TrainLLM/ModelCkpt/glm/glm4-8b-chat"
    )

    synthesizer_llm_client = OpenAIClient(
        model_name="glm4-9b",
        api_key="NuistMathAutoModelForCausalLM",
        base_url="http://172.16.107.15:23333/v1",
        tokenizer=tokenizer_instance,
    )

    asyncio.run(post_process(
        synthesizer_llm_client,
        "/data/lzm/DrugRecommend/resource/output/submit/few_shot_glm4.json",
        "/data/lzm/DrugRecommend/src/worker/dataset/pre_drug.json",
        "/data/lzm/DrugRecommend/src/data/pre_drug_mapping.json",
        SAVE_PATH,
        max_concurrent=20  # âš¡ æé«˜å¹¶å‘
    ))
